{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Зависимости и т д"
      ],
      "metadata": {
        "id": "o5UQ2lERhYL8"
      },
      "id": "o5UQ2lERhYL8"
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/kechsin/TinyDialogues.git"
      ],
      "metadata": {
        "id": "iNmB8MuBFibS",
        "outputId": "edc797e7-6d0b-419a-d66a-6e67bf8131ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "iNmB8MuBFibS",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'TinyDialogues' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd TinyDialogues"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3cKsCYUb2FR",
        "outputId": "71ad534e-98e8-45ef-b0c5-d6378dfd6ca3"
      },
      "id": "W3cKsCYUb2FR",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TinyDialogues\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y transformers tokenizers\n",
        "!pip install transformers==4.57.3 tokenizers==0.22.0"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hJywo42M-iV0",
        "outputId": "05a58f9a-ab46-4704-c3c8-ad2a54463098",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "hJywo42M-iV0",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: transformers 4.57.3\n",
            "Uninstalling transformers-4.57.3:\n",
            "  Successfully uninstalled transformers-4.57.3\n",
            "Found existing installation: tokenizers 0.22.0\n",
            "Uninstalling tokenizers-0.22.0:\n",
            "  Successfully uninstalled tokenizers-0.22.0\n",
            "Collecting transformers==4.57.3\n",
            "  Using cached transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
            "Collecting tokenizers==0.22.0\n",
            "  Using cached tokenizers-0.22.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.3) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.3) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.3) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.3) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.3) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.3) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.3) (2.32.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.3) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.3) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.3) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.3) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.3) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.3) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.3) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.3) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.3) (2025.11.12)\n",
            "Using cached transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
            "Using cached tokenizers-0.22.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [transformers]\n",
            "\u001b[1A\u001b[2KSuccessfully installed tokenizers-0.22.0 transformers-4.57.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r transformers/examples/pytorch/language-modeling/requirements.txt\n",
        "!pip install accelerate tokenizers nltk evaluate\n",
        "!pip install numpy==1.24.2"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8E2H8p8RTmw6",
        "outputId": "60e9d1af-c70d-4e5e-f681-6d25b8be6319"
      },
      "id": "8E2H8p8RTmw6",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from -r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (1.12.0)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.12/dist-packages (from -r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (2.9.0+cu126)\n",
            "Requirement already satisfied: datasets>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from -r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (4.0.0)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.12/dist-packages (from -r transformers/examples/pytorch/language-modeling/requirements.txt (line 4)) (0.2.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from -r transformers/examples/pytorch/language-modeling/requirements.txt (line 5)) (5.29.5)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (from -r transformers/examples/pytorch/language-modeling/requirements.txt (line 6)) (0.4.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r transformers/examples/pytorch/language-modeling/requirements.txt (line 7)) (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.12.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.12.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.12.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.12.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (6.0.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.12.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (0.36.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.12.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (3.5.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (0.70.16)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (3.13.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 7)) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 7)) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 7)) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (3.11)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=0.12.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.3->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 2)) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=1.8.0->-r transformers/examples/pytorch/language-modeling/requirements.txt (line 3)) (1.17.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.12/dist-packages (0.22.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.3)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu126)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.36.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (3.11)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.11.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Collecting numpy==1.24.2\n",
            "  Using cached numpy-1.24.2.tar.gz (10.9 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m No available output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31mERROR: Failed to build 'numpy' when getting requirements to build wheel\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучаем GPT2 на TinyDialogues (синтетических данных)"
      ],
      "metadata": {
        "id": "wOzMM3R8hp93"
      },
      "id": "wOzMM3R8hp93"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Загрузка датасета и токенизатор"
      ],
      "metadata": {
        "id": "PrzueZYzhxws"
      },
      "id": "PrzueZYzhxws"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "tDODUwJRCiSG"
      },
      "id": "tDODUwJRCiSG",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = load_dataset(\"styfeng/TinyDialogues\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTsUiNYnAOH9",
        "outputId": "7b08e29a-c72c-44ca-c700-29712f467c08"
      },
      "id": "cTsUiNYnAOH9",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds['train'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSo6abZRAuqD",
        "outputId": "24b63396-f40c-4db9-8dca-f18565cabd20"
      },
      "id": "WSo6abZRAuqD",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': '**Dad**: \"Hey sweetie, do you want to paint with Daddy?\" \\\\n\\\\n **Child**: \"Paint!\" \\\\n\\\\n **Dad**: \"Yes, we\\'ll use these brushes. But first, let\\'s put on your apron so we don\\'t get paint on your clothes.\" \\\\n\\\\n **Child**: \"Apron!\" \\\\n\\\\n **Mom**: \"Breakfast is almost ready! Who wants pancakes?\" \\\\n\\\\n **Child**: \"Pancake!\" \\\\n\\\\n **Dad**: \"We\\'ll eat first, then paint. Let\\'s wash hands before we eat, okay?\" \\\\n\\\\n **Child**: \"Wash!\" \\\\n\\\\n **Mom**: \"Careful, the pancakes are hot. We\\'ll let them cool a little bit.\" \\\\n\\\\n **Child**: \"Hot?\" \\\\n\\\\n **Mom**: \"Yes, hot. But they\\'ll be just right soon. Here\\'s your plate.\" \\\\n\\\\n **Child**: \"Eat pancake!\" \\\\n\\\\n **Dad**: \"After pancakes, we can start our painting. What colors do you want to use?\" \\\\n\\\\n **Child**: \"Blue!\" \\\\n\\\\n **Mom**: \"Blue is a great choice. Finish up and then you can paint with blue.\" \\\\n\\\\n **Child**: \"Blue paint!\" \\\\n\\\\n **Dad**: \"Alright, pancakes are done. Let\\'s clean up and then it\\'s painting time!\" \\\\n\\\\n **Child**: \"Paint time!\" <|endoftext|>'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_folder = \"TD\"\n",
        "os.makedirs(output_folder, exist_ok=True)"
      ],
      "metadata": {
        "id": "VtYWSf2dCdwS"
      },
      "id": "VtYWSf2dCdwS",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(os.path.join(output_folder, \"train.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    for text in ds[\"train\"]:\n",
        "        f.write(text[\"text\"] + \"<|endoftext|>\" + \"\\n\")"
      ],
      "metadata": {
        "id": "wOVLQoQzA2SM"
      },
      "id": "wOVLQoQzA2SM",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(os.path.join(output_folder, \"val.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    for text in ds[\"validation\"]:\n",
        "        f.write(text[\"text\"] + \"<|endoftext|>\" + \"\\n\")"
      ],
      "metadata": {
        "id": "ChLOzYTsC7cr"
      },
      "id": "ChLOzYTsC7cr",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/tokenizers/train_GPT2_tokenizer.py TD/train.txt TD/val.txt my_TD_tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNV2m02lDCYc",
        "outputId": "2c31b93a-a49b-4170-9897-097a72378f8f"
      },
      "id": "jNV2m02lDCYc",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenizer_config.json: 100% 26.0/26.0 [00:00<00:00, 157kB/s]\n",
            "config.json: 100% 665/665 [00:00<00:00, 3.43MB/s]\n",
            "vocab.json: 100% 1.04M/1.04M [00:00<00:00, 1.77MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 2.19MB/s]\n",
            "tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 6.49MB/s]\n",
            "['def', 'Ġadd', '_', 'n', 'umbers', '(', 'a', ',', 'Ġb', '):', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġ\"\"\"', 'Add', 'Ġthe', 'Ġtwo', 'Ġnumbers', 'Ġ`', 'a', '`', 'Ġand', 'Ġ`', 'b', '`', '.\"', '\"\"', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġreturn', 'Ġa', 'Ġ+', 'Ġb']\n",
            "129732\n",
            "\u001b[2K[00:00:00] Tokenize words                 ██████████████████ 93421    /    93421\n",
            "\u001b[2K[00:00:00] Count pairs                    ██████████████████ 93421    /    93421\n",
            "\u001b[2K[00:00:01] Compute merges                 ██████████████████ 51742    /    51742\n",
            "All special tokens: ['<|endoftext|>', '<UNK>']\n",
            "BOS token: <|endoftext|>\n",
            "EOS token: <|endoftext|>\n",
            "PAD token: None\n",
            "UNK token: <|endoftext|>\n",
            "SEP token: None\n",
            "CLS token: None\n",
            "MASK token: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/tokenizers/test_GPT2_tokenizer.py my_TD_tokenizer"
      ],
      "metadata": {
        "collapsed": true,
        "id": "W1cd7QGSGmGn",
        "outputId": "a72327df-2f5e-40d1-b5b5-594ac9c0d44d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "W1cd7QGSGmGn",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/TinyDialogues/TinyDialogues/scripts/tokenizers/test_GPT2_tokenizer.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Я посмотрела в коде этого теста на то, какие там предложения, и он их правильно написал, всё хорошо.\n",
        "Можем ещё сравнить с токенайзером обученном ими (на тех же данных, и я ничего не меняла, так что должно быть то же самое)"
      ],
      "metadata": {
        "id": "53xkj05SIkTG"
      },
      "id": "53xkj05SIkTG"
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/tokenizers/test_GPT2_tokenizer.py tokenizers/GPT2_tinydialogue"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xK_s3mYZIj0A",
        "outputId": "b8420262-d053-4c1e-f048-977a4e922b2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "xK_s3mYZIj0A",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " tokenizers/GPT2_tinydialogue \n",
            "\n",
            "['do', 'Ġyou', 'Ġwant', 'Ġto', 'Ġlook', 'Ġat', 'Ġthat', 'Ġit', 'Ġsays', 'Ġlook', 'Ġ', '?']\n",
            "do you want to look at that it says look ? \n",
            "\n",
            "['The', 'Ġyellow', '-', 'billed', 'Ġshri', 'ke', 'Ġ(', \"'\", 'Cor', 'vin', 'ella', 'Ġcor', 'v', 'ina', \"')\", 'Ġis', 'Ġa', 'Ġlarge', 'Ġpasser', 'ine', 'Ġbird', 'Ġin', 'Ġthe', 'Ġshri', 'ke', 'Ġfamily', '.', 'ĠIt', 'Ġis', 'Ġsometimes', 'Ġknown', 'Ġas', 'Ġthe', 'Ġlong', '-', 'tailed', 'Ġshri', 'ke', ',', 'Ġbut', 'Ġthis', 'Ġis', 'Ġto', 'Ġbe', 'Ġdiscouraged', ',', 'Ġsince', 'Ġit', 'Ġinvites', 'Ġconfusion', 'Ġwith', 'Ġthe', 'Ġlong', '-', 'tailed', 'Ġshri', 'ke', ',', \"Ġ'\", 'L', 'an', 'ius', 'Ġsc', 'ha', 'ch', \"',\", 'Ġof', 'Ġtropical', 'Ġsouthern', 'ĠAsia', '.', 'ĠThe', 'Ġyellow', '-', 'billed', 'Ġshri', 'ke', 'Ġis', 'Ġa', 'Ġcommon', 'Ġresident', 'Ġbreeding', 'Ġbird', 'Ġin', 'Ġtropical', 'ĠAfrica', 'Ġfrom', 'ĠSen', 'eg', 'al', 'Ġeast', 'ward', 's', 'Ġto', 'ĠU', 'g', 'anda', 'Ġand', 'Ġlocally', 'Ġin', 'Ġwesternmost', 'ĠK', 'eny', 'a', '.', 'ĠIt', 'Ġfrequ', 'ents', 'Ġforest', 'Ġand', 'Ġother', 'Ġhabitats', 'Ġwith', 'Ġtrees', '.']\n",
            "The yellow-billed shrike ('Corvinella corvina') is a large passerine bird in the shrike family. It is sometimes known as the long-tailed shrike, but this is to be discouraged, since it invites confusion with the long-tailed shrike, 'Lanius schach', of tropical southern Asia. The yellow-billed shrike is a common resident breeding bird in tropical Africa from Senegal eastwards to Uganda and locally in westernmost Kenya. It frequents forest and other habitats with trees. \n",
            "\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1670 > 1024). Running this sequence through the model will result in indexing errors\n",
            "['**', 'MO', 'T', '**:', 'Ġjust', 'Ġlike', 'Ġyour', 'Ġbook', 'Ġat', 'Ġhome', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġdo', 'Ġyou', 'Ġwanna', 'Ġlook', 'Ġat', 'Ġthat', 'Ġit', 'Ġsays', 'Ġlook', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġsee', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġthere', \"'s\", 'Ġa', 'Ġface', 'Ġwith', 'Ġglass', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġah', 'ha', 'h', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġlook', 'Ġthere', \"'s\", 'ĠP', 'ooh', '_', 'Bear', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġthere', \"'s\", 'Ġa', 'Ġbaby', 'Ġbear', 'Ġwith', 'Ġhis', 'Ġbottle', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġwho', \"'s\", 'Ġthat', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġis', 'Ġthat', 'ĠChi', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġah', 'ha', 'h', 'ĠI', 'Ġthink', 'ĠI', 'Ġsee', 'ĠChi', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġthere', 'Ġhe', 'Ġis', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġyay', 'Ġyay', 'Ġthere', 'Ġhe', 'Ġis', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġyou', 'Ġsee', 'Ġyourself', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġthat', \"'s\", 'Ġmy', 'Ġpretty', 'Ġbaby', 'Ġboy', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'ĠI', \"'m\", 'Ġsorry', 'Ġthat', \"'s\", 'Ġhandsome', 'Ġbaby', 'Ġboy', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġyou', 'Ġlike', 'Ġthat', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġyay', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġlook', 'Ġthere', \"'s\", 'Ġa', 'Ġbunny', '+', 'rabb', 'it', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġsee', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġthere', \"'s\", 'Ġkitty', '+', 'cat', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġoh', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġkitty', '+', 'cat', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġand', 'Ġwho', \"'s\", 'Ġthis', 'Ġit', \"'s\", 'Ġa', 'Ġbaby', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġit', \"'s\", 'Ġa', 'Ġbaby', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġyay', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġwanna', 'Ġlook', 'Ġat', 'Ġthat', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġoh', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġdoes', 'Ġit', 'Ġfit', 'Ġyour', 'Ġmouth', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġlet', \"'s\", 'Ġsee', 'Ġwhat', 'Ġelse', 'Ġthere', 'Ġis', 'Ġin', 'Ġhere', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'ĠThere', \"'s\", 'Ġa', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġa', 'Ġpink', 'Ġpig', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġoink', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġyou', 'Ġlike', 'Ġthat', 'Ġbook', 'Ġit', \"'s\", 'Ġvery', 'Ġred', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġred', 'Ġis', 'Ġa', 'Ġgood', 'Ġthing', 'Ġisn', \"'t\", 'Ġit', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġoink', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġyou', 'Ġwant', 'Ġyour', 'Ġbook', 'Ġback', 'Ġdon', \"'t\", 'Ġyou', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġlet', \"'s\", 'Ġsee', 'Ġdo', 'Ġyou', 'Ġwanna', 'Ġsee', 'Ġwho', 'Ġthis', 'Ġis', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġthis', 'Ġis', 'ĠBig', '_', 'Bird', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġenough', 'Ġwith', 'Ġthat', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġcan', 'Ġyou', 'Ġread', 'Ġyour', 'Ġbook', 'Ġagain', 'Ġyou', 'Ġlike', 'Ġthe', 'Ġbook', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġlook', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġsee', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġyou', 'Ġwanna', 'Ġsee', 'Ġif', 'Ġit', 'Ġfits', 'Ġin', 'Ġyour', 'Ġmouth', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġis', 'Ġthat', 'Ġwhat', 'Ġyou', 'Ġwanna', 'Ġsee', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġoh', 'Ġthat', \"'s\", 'Ġtoo', 'Ġbig', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġwhat', 'Ġdo', 'Ġyou', 'Ġknow', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġwanna', 'Ġsee', 'Ġwhat', \"'s\", 'Ġinside', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġyou', 'Ġwanna', 'Ġhold', 'Ġit', 'Ġlike', 'Ġthat', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġwhoop', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġhere', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġ', '<UNK>', 'Ġface', 'Ġglass', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġthere', \"'s\", 'Ġbaby', 'Ġbear', 'Ġwith', 'Ġhis', 'Ġbottle', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġsee', 'Ġbaby', 'Ġbear', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġyay', 'Ġsee', 'Ġbaby', 'Ġbear', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġand', 'Ġthen', 'Ġwho', \"'s\", 'Ġthis', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġwho', \"'s\", 'Ġthat', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġwhose', 'Ġpicture', 'Ġis', 'Ġthat', 'Ġdo', 'Ġyou', 'Ġsee', 'Ġyourself', 'Ġin', 'Ġthe', 'Ġmirror', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġthat', \"'s\", 'ĠChi', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġ', '<UNK>', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġstill', 'Ġwanna', 'Ġsee', 'Ġif', 'Ġit', 'Ġfits', 'Ġin', 'Ġyour', 'Ġmouth', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġoh', 'Ġwhat', 'Ġdo', 'Ġyou', 'Ġthink', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġdoes', 'Ġit', 'Ġfit', 'Ġnice', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġthat', \"'s\", 'Ġsuch', 'Ġa', 'Ġpretty', 'Ġred', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'ĠIt', \"'s\", 'Ġred', 'Ġlike', 'Ġyour', 'Ġsocks', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġand', 'Ġred', 'Ġlike', 'Ġyour', 'Ġthe', 'Ġed', 'ging', 'Ġon', 'Ġyour', 'Ġoutfit', 'Ġand', 'Ġall', 'Ġthose', 'Ġother', 'Ġthings', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġyay', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġlook', 'Ġhere', \"'s\", 'Ġsomething', 'Ġelse', 'ĠI', 'Ġknow', 'Ġyou', 'Ġlike', 'Ġat', 'Ġhome', 'Ġcan', 'Ġyou', 'Ġlook', 'Ġat', 'Ġthis', 'Ġone', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġyou', 'Ġjust', 'Ġlove', 'Ġthat', 'Ġbook', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġthat', 'Ġis', 'Ġso', 'Ġmuch', 'Ġfun', 'Ġthe', 'Ġway', 'Ġthat', 'Ġfits', 'Ġin', 'Ġyour', 'Ġmouth', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġdo', 'Ġyou', 'Ġsee', 'ĠCookie', '_', 'Monster', 'Ġover', 'Ġthere', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġis', 'Ġthat', 'Ġwho', 'Ġyou', 'Ġare', 'Ġlooking', 'Ġat', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġthat', 'Ġfits', 'Ġin', 'Ġyour', 'Ġmouth', 'Ġoh', 'Ġthat', \"'s\", 'Ġjust', 'Ġgreat', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġthat', \"'s\", 'Ġjust', 'Ġgreat', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġit', 'Ġfits', 'Ġin', 'Ġyour', 'Ġmouth', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġhey', 'Ġcan', 'Ġwe', 'Ġtry', 'Ġthis', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'ĠI', \"'m\", 'Ġgoing', 'Ġto', 'Ġput', 'Ġyour', 'Ġhand', 'Ġon', 'Ġthis', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġyou', 'Ġcan', 'Ġgrab', 'Ġthis', 'Ġthis', 'Ġis', 'Ġpretty', 'Ġneat', 'Ġbecause', 'Ġyou', 'Ġcan', 'Ġgrab', 'Ġit', 'Ġjust', 'Ġright', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġthere', 'Ġyou', 'Ġgot', 'Ġit', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġgood', 'Ġjob', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġyou', 'Ġwant', 'Ġthis', 'Ġback', 'Ġin', 'Ġyour', 'Ġhand', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġyou', 'Ġwant', 'Ġit', 'Ġin', 'Ġthis', 'Ġhand', 'Ġmaybe', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġlet', \"'s\", 'Ġopen', 'Ġyour', 'Ġfingers', 'Ġa', 'Ġlittle', 'Ġbit', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġcan', 'ĠI', 'Ġhelp', 'Ġyou', 'Ġby', 'Ġopening', 'Ġyour', 'Ġfingers', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġthere', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġyou', 'Ġgot', 'Ġit', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġoh', 'Ġyou', 'Ġgot', 'Ġit', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġgood', 'Ġfor', 'Ġyou', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġyou', 'Ġwant', 'Ġit', 'Ġto', 'Ġmake', 'Ġnoise', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġthere', 'Ġare', 'Ġsome', 'Ġbeautiful', 'Ġcolors', 'Ġin', 'Ġhere', 'Ġaren', \"'t\", 'Ġthere', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġthat', 'Ġis', 'Ġso', 'Ġneat', 'Ġthe', 'Ġway', 'Ġit', 'Ġdoes', 'Ġthat', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġyou', 'Ġwant', 'Ġit', 'Ġback', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġ', '<UNK>', 'Ġin', 'Ġyour', 'Ġhand', 'Ġyou', 'Ġcan', 'Ġgrab', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġ', '<UNK>', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġoh', 'Ġyou', 'Ġgot', 'Ġit', 'Ġyou', 'Ġgot', 'Ġit', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġyay', 'ĠChi', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġdo', 'Ġyou', 'Ġlike', 'Ġsitting', 'Ġup', 'Ġin', 'Ġthat', 'Ġseat', 'Ġthat', \"'s\", 'Ġpretty', 'Ġneat', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġ', '<UNK>', 'Ġyou', 'Ġwould', 'Ġlike', 'Ġit', 'Ġto', 'Ġbe', 'Ġable', 'Ġto', 'Ġsit', 'Ġup', 'Ġmore', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġyou', \"'re\", 'Ġalmost', 'Ġthere', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġalmost', 'Ġ', '<UNK>', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġyou', 'Ġgot', 'Ġit', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġhere', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġyay', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġoh', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġis', 'Ġthat', 'Ġso', 'Ġfun', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġyou', 'Ġwanna', 'Ġcatch', 'Ġit', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġcatch', 'Ġit', 'Ġcatch', 'Ġit', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġyou', 'Ġgot', 'Ġit', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġyay', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'ĠI', 'Ġlike', 'Ġthe', 'Ġsound', 'Ġthat', 'Ġmakes', 'ĠI', 'Ġthink', 'Ġyou', 'Ġlike', 'Ġit', 'Ġtoo', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġdo', 'Ġyou', 'Ġshake', 'Ġ', '<UNK>', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġyou', 'Ġgot', 'Ġit', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġwe', 'Ġhave', 'Ġone', 'Ġof', 'Ġthose', 'Ġat', 'Ġhome', 'Ġfor', 'Ġyou', 'Ġtoo', 'Ġif', 'Ġwe', 'Ġcould', 'Ġjust', 'Ġkeep', 'Ġthat', 'Ġtwo', 'Ġyear', 'Ġold', 'Ġsister', 'Ġof', 'Ġyours', 'Ġfrom', 'Ġrunning', 'Ġoff', 'Ġwith', 'Ġit', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġyou', 'Ġbetter', 'Ġlearn', 'Ġto', 'Ġhang', 'Ġon', 'Ġto', 'Ġyour', 'Ġtoys', 'Ġreal', 'Ġwell', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġor', 'Ġshe', \"'ll\", 'Ġget', 'Ġthem', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġyou', \"'ll\", 'Ġha', 'ft', 'a', 'Ġtackle', 'Ġher', 'Ġand', 'Ġget', 'Ġthem', 'Ġaway', 'Ġfrom', 'Ġher', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġwhat', 'Ġyou', 'Ġdoing', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġoh', 'Ġdid', 'Ġit', 'Ġrun', 'Ġaway', 'Ġfrom', 'Ġyou', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġyou', 'Ġgot', 'Ġit', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġis', 'Ġthat', 'Ġfun', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġis', 'Ġthat', 'Ġa', 'Ġfun', 'Ġtoy', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġwhat', \"'s\", 'Ġthat', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġ', '<UNK>', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġoh', 'Ġdear', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġoh', 'Ġdear', 'Ġthat', \"'s\", 'Ġso', 'Ġmessy', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġso', 'Ġmessy', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġyes', 'Ġall', 'Ġthat', 'Ġdrool', 'ĠI', 'Ġjust', 'Ġdon', \"'t\", 'Ġknow', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġm', 'm', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġah', 'ha', 'h', 'Ġyou', 'Ġlike', 'Ġthat', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġah', 'ha', 'h', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġoh', 'Ġwhat', 'Ġbaby', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġyou', 'Ġnot', 'Ġsure', 'Ġabout', 'Ġthat', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġwould', 'Ġyou', 'Ġlike', 'Ġto', 'Ġsit', 'Ġup', 'Ġa', 'Ġlittle', 'Ġbit', 'Ġmore', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġthat', \"'s\", 'Ġkind', 'Ġof', 'Ġa', 'Ġfunny', 'Ġthing', 'Ġto', 'Ġsit', 'Ġin', 'Ġisn', \"'t\", 'Ġit', 'Ġ', 'Ċ', 'Ċ', 'Ġ**', 'MO', 'T', '**:', 'Ġyou', 'Ġlike', 'Ġthat', 'Ġbetter', 'Ġ', '<|endoftext|>']\n",
            "**MOT**: just like your book at home \n",
            "\n",
            " **MOT**: do you wanna look at that it says look \n",
            "\n",
            " **MOT**: see \n",
            "\n",
            " **MOT**: there's a face with glass \n",
            "\n",
            " **MOT**: ahhah \n",
            "\n",
            " **MOT**: look there's Pooh_Bear \n",
            "\n",
            " **MOT**: there's a baby bear with his bottle \n",
            "\n",
            " **MOT**: who's that \n",
            "\n",
            " **MOT**: is that Chi \n",
            "\n",
            " **MOT**: ahhah I think I see Chi \n",
            "\n",
            " **MOT**: there he is \n",
            "\n",
            " **MOT**: yay yay there he is \n",
            "\n",
            " **MOT**: you see yourself \n",
            "\n",
            " **MOT**: that's my pretty baby boy \n",
            "\n",
            " **MOT**: I'm sorry that's handsome baby boy \n",
            "\n",
            " **MOT**: you like that \n",
            "\n",
            " **MOT**: yay \n",
            "\n",
            " **MOT**: look there's a bunny+rabbit \n",
            "\n",
            " **MOT**: see \n",
            "\n",
            " **MOT**: there's kitty+cat \n",
            "\n",
            " **MOT**: oh \n",
            "\n",
            " **MOT**: kitty+cat \n",
            "\n",
            " **MOT**: and who's this it's a baby \n",
            "\n",
            " **MOT**: it's a baby \n",
            "\n",
            " **MOT**: yay \n",
            "\n",
            " **MOT**: wanna look at that \n",
            "\n",
            " **MOT**: oh \n",
            "\n",
            " **MOT**: does it fit your mouth \n",
            "\n",
            " **MOT**: let's see what else there is in here \n",
            "\n",
            " **MOT**: There's a \n",
            "\n",
            " **MOT**: a pink pig \n",
            "\n",
            " **MOT**: oink \n",
            "\n",
            " **MOT**: you like that book it's very red \n",
            "\n",
            " **MOT**: red is a good thing isn't it \n",
            "\n",
            " **MOT**: oink \n",
            "\n",
            " **MOT**: you want your book back don't you \n",
            "\n",
            " **MOT**: let's see do you wanna see who this is \n",
            "\n",
            " **MOT**: this is Big_Bird \n",
            "\n",
            " **MOT**: enough with that \n",
            "\n",
            " **MOT**: can you read your book again you like the book \n",
            "\n",
            " **MOT**: look \n",
            "\n",
            " **MOT**: see \n",
            "\n",
            " **MOT**: you wanna see if it fits in your mouth \n",
            "\n",
            " **MOT**: is that what you wanna see \n",
            "\n",
            " **MOT**: oh that's too big \n",
            "\n",
            " **MOT**: what do you know \n",
            "\n",
            " **MOT**: wanna see what's inside \n",
            "\n",
            " **MOT**: you wanna hold it like that \n",
            "\n",
            " **MOT**: whoop \n",
            "\n",
            " **MOT**: here \n",
            "\n",
            " **MOT**: <UNK> face glass \n",
            "\n",
            " **MOT**: there's baby bear with his bottle \n",
            "\n",
            " **MOT**: see baby bear \n",
            "\n",
            " **MOT**: yay see baby bear \n",
            "\n",
            " **MOT**: and then who's this \n",
            "\n",
            " **MOT**: who's that \n",
            "\n",
            " **MOT**: whose picture is that do you see yourself in the mirror \n",
            "\n",
            " **MOT**: that's Chi \n",
            "\n",
            " **MOT**: <UNK> \n",
            "\n",
            " **MOT**: still wanna see if it fits in your mouth \n",
            "\n",
            " **MOT**: oh what do you think \n",
            "\n",
            " **MOT**: does it fit nice \n",
            "\n",
            " **MOT**: that's such a pretty red \n",
            "\n",
            " **MOT**: It's red like your socks \n",
            "\n",
            " **MOT**: and red like your the edging on your outfit and all those other things \n",
            "\n",
            " **MOT**: yay \n",
            "\n",
            " **MOT**: look here's something else I know you like at home can you look at this one \n",
            "\n",
            " **MOT**: you just love that book \n",
            "\n",
            " **MOT**: that is so much fun the way that fits in your mouth \n",
            "\n",
            " **MOT**: do you see Cookie_Monster over there \n",
            "\n",
            " **MOT**: is that who you are looking at \n",
            "\n",
            " **MOT**: that fits in your mouth oh that's just great \n",
            "\n",
            " **MOT**: that's just great \n",
            "\n",
            " **MOT**: it fits in your mouth \n",
            "\n",
            " **MOT**: hey can we try this \n",
            "\n",
            " **MOT**: I'm going to put your hand on this \n",
            "\n",
            " **MOT**: you can grab this this is pretty neat because you can grab it just right \n",
            "\n",
            " **MOT**: there you got it \n",
            "\n",
            " **MOT**: good job \n",
            "\n",
            " **MOT**: you want this back in your hand \n",
            "\n",
            " **MOT**: you want it in this hand maybe \n",
            "\n",
            " **MOT**: let's open your fingers a little bit \n",
            "\n",
            " **MOT**: can I help you by opening your fingers \n",
            "\n",
            " **MOT**: there \n",
            "\n",
            " **MOT**: you got it \n",
            "\n",
            " **MOT**: oh you got it \n",
            "\n",
            " **MOT**: good for you \n",
            "\n",
            " **MOT**: you want it to make noise \n",
            "\n",
            " **MOT**: there are some beautiful colors in here aren't there \n",
            "\n",
            " **MOT**: that is so neat the way it does that \n",
            "\n",
            " **MOT**: you want it back \n",
            "\n",
            " **MOT**: <UNK> in your hand you can grab \n",
            "\n",
            " **MOT**: <UNK> \n",
            "\n",
            " **MOT**: oh you got it you got it \n",
            "\n",
            " **MOT**: yay Chi \n",
            "\n",
            " **MOT**: do you like sitting up in that seat that's pretty neat \n",
            "\n",
            " **MOT**: <UNK> you would like it to be able to sit up more \n",
            "\n",
            " **MOT**: you're almost there \n",
            "\n",
            " **MOT**: almost <UNK> \n",
            "\n",
            " **MOT**: you got it \n",
            "\n",
            " **MOT**: here \n",
            "\n",
            " **MOT**: yay \n",
            "\n",
            " **MOT**: oh \n",
            "\n",
            " **MOT**: is that so fun \n",
            "\n",
            " **MOT**: you wanna catch it \n",
            "\n",
            " **MOT**: catch it catch it \n",
            "\n",
            " **MOT**: you got it \n",
            "\n",
            " **MOT**: yay \n",
            "\n",
            " **MOT**: I like the sound that makes I think you like it too \n",
            "\n",
            " **MOT**: do you shake <UNK> \n",
            "\n",
            " **MOT**: you got it \n",
            "\n",
            " **MOT**: we have one of those at home for you too if we could just keep that two year old sister of yours from running off with it \n",
            "\n",
            " **MOT**: you better learn to hang on to your toys real well \n",
            "\n",
            " **MOT**: or she'll get them \n",
            "\n",
            " **MOT**: you'll hafta tackle her and get them away from her \n",
            "\n",
            " **MOT**: what you doing \n",
            "\n",
            " **MOT**: oh did it run away from you \n",
            "\n",
            " **MOT**: you got it \n",
            "\n",
            " **MOT**: is that fun \n",
            "\n",
            " **MOT**: is that a fun toy \n",
            "\n",
            " **MOT**: what's that \n",
            "\n",
            " **MOT**: <UNK> \n",
            "\n",
            " **MOT**: oh dear \n",
            "\n",
            " **MOT**: oh dear that's so messy \n",
            "\n",
            " **MOT**: so messy \n",
            "\n",
            " **MOT**: yes all that drool I just don't know \n",
            "\n",
            " **MOT**: mm \n",
            "\n",
            " **MOT**: ahhah you like that \n",
            "\n",
            " **MOT**: ahhah \n",
            "\n",
            " **MOT**: oh what baby \n",
            "\n",
            " **MOT**: you not sure about that \n",
            "\n",
            " **MOT**: would you like to sit up a little bit more \n",
            "\n",
            " **MOT**: that's kind of a funny thing to sit in isn't it \n",
            "\n",
            " **MOT**: you like that better <|endoftext|> \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Да, вроде одинаково"
      ],
      "metadata": {
        "id": "xE8BboKbKKDq"
      },
      "id": "xE8BboKbKKDq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучаем модель"
      ],
      "metadata": {
        "id": "6pcidWMZh6R1"
      },
      "id": "6pcidWMZh6R1"
    },
    {
      "cell_type": "code",
      "source": [
        "!bash scripts/language_model_training/GPT2_CHILDES_4-GPUs_train.sh \\\n",
        "  TD/train.txt TD/val.txt tokenizers/GPT2_tinydialogue \\\n",
        "  tokenizers/GPT2-small_config GPT2_TD_output \\\n",
        "  gpt2 1e-04 1 8 42"
      ],
      "metadata": {
        "id": "7jXjCBAsHzLX",
        "outputId": "04063e61-3018-4841-af79-ff470dd290b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "7jXjCBAsHzLX",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1e-04\n",
            "gpt2\n",
            "1\n",
            "8\n",
            "42\n",
            "2025-12-26 14:10:14.500143: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1766758214.532518    5628 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1766758214.543124    5628 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1766758214.561572    5628 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766758214.561614    5628 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766758214.561619    5628 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766758214.561622    5628 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-26 14:10:14.566343: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/TinyDialogues/scripts/language_model_training/examples/run_clm_no_shuffling.py\", line 40, in <module>\n",
            "    from transformers import (\n",
            "ImportError: cannot import name 'is_torch_tpu_available' from 'transformers' (/usr/local/lib/python3.12/dist-packages/transformers/__init__.py)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}